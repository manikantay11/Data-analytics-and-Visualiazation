Hadoop installation and Usage :

Step by step procedure for HADOOP installation on
UBUNTU
Procedure:
Open terminal in UBUNTU and execute the fallowing commands one by one 
 1)sudo apt update
2)sudo apt install openjdk-8-jdk -y
3)java -version; javac -version
4)sudo apt install openssh-server openssh-client -y
5)ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa
6)cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
7)chmod 0600 ~/.ssh/authorized_keys
8)ssh localhost
9)wget https://downloads.apache.org/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz
10)tar xzf hadoop-3.2.1.tar.gz
11)sudo nano .bashrc
#Hadoop Related Options
export HADOOP_HOME=/home/hadoop-3.2.1
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
export HADOOP_OPTS=”-Djava.library.path=$HADOOP_HOME/lib/native”
12)source ~/.bashrc
13)sudo nano $HADOOP_HOME/etc/hadoop/hadoop-env.sh
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

which javac
readlink -f /usr/bin/javac

14)sudo nano $HADOOP_HOME/etc/hadoop/core-site.xml
&lt;configuration&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
  &lt;value&gt;/home/tmpdata&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;fs.default.name&lt;/name&gt;
  &lt;value&gt;hdfs://127.0.0.1:9000&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
15)sudo nano $HADOOP_HOME/etc/hadoop/hdfs-site.xml
&lt;configuration&gt;
&lt;property&gt;
  &lt;name&gt;dfs.data.dir&lt;/name&gt;
  &lt;value&gt;/home/dfsdata/namenode&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;dfs.data.dir&lt;/name&gt;
  &lt;value&gt;/home/dfsdata/datanode&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;dfs.replication&lt;/name&gt;
  &lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
16)sudo nano $HADOOP_HOME/etc/hadoop/mapred-site.xml
&lt;configuration&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
  &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;

17)sudo nano $HADOOP_HOME/etc/hadoop/yarn-site.xml
&lt;configuration&gt;
&lt;property&gt;
  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
  &lt;value&gt;mapreduce_shuffle&lt;/value&gt;

&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
  &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
  &lt;value&gt;127.0.0.1&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;yarn.acl.enable&lt;/name&gt;
  &lt;value&gt;0&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;   
 
&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP
_CONF_DIR,CLASSPATH_PERPEND_DISTCACHE,HADOOP_YARN_HOME,HADOO
P_MAPRED_HOME&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
18)hdfs namenode -format
Navigate to the hadoop-3.2.1/sbin directory
19)./start-dfs.sh
20)./start-yarn.sh
21)jps
22)http://localhost:9870
23)http://localhost:9864
24)http://localhost:8088
